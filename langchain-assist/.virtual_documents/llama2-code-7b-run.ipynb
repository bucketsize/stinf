


from langchain_community.llms import Ollama
from langchain_core.output_parsers import StrOutputParser
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate


llm = Ollama(model="codellama")


p_sys = """you are a programmer who can write functionally correct code"""
t_sys = """<s>[INST] <<SYS>>
{p_sys}
<</SYS>>

{p_user} [/INST]"""

prompt = PromptTemplate(
    template=t_sys,
    input_variables=["p_sys", "p_user"]
)



chain = prompt | llm | StrOutputParser()


q1 = "write a python program to print prime number up to an number N"
q2 = "write a python program to create a virtualbox diskimage and copy linux root filesystem to the virtualbox image"
q3 = """ 
write a java program to send a http request of a person's salary, age and job to a server and 
parse the response that has credit score in range of 0 to 1.0 and validity time period in days.
Then assign a tag of 'allow' if the credit score is between 0.7 and 1, 'suspect' if 
the credit score is between 0.3 and 0.7, 'deny' is the credit score is in between 0 and 0.3.
And persist the credit score, validity and tag to a relational db using jpa named query.
"""
for chunk in chain.stream({"p_sys": p_sys, "p_user": q3}):
    print(chunk, end="", flush=True) 
