


get_ipython().getoutput("curl https://ollama.ai/install.sh | sh")


get_ipython().getoutput("ln -s /mnt/data/ws/llama.cpp/models/ggml-codellama-7b-q4_0.bin /usr/share/ollama/.ollama/models/")


get_ipython().getoutput("echo "FROM /mnt/data/ws/llama.cpp/models/ggml-codellama-7b-q4_0.bin"  > llama.Modelfile")


get_ipython().getoutput("ollama create codellama -f codellama.Modelfile")


get_ipython().getoutput("ollama run codellama")
